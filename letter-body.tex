Thank you for taking your time to read my application. My PhD on addressing distribution shift in robotic imitation learning will be wrapping up within the next few months, and I would love to work with the amazing team at 1X. I am confident that my experience would make me a good fit. I have completed extensive research and applied work with manipulators, both mobile and static, in both the real world and in simulation. My research has focused primarily on imitation learning, (inverse) reinforcement learning, and human-robot interaction to generate strong policies. Since I come from a lab where these lines of research were not the status quo, I was also responsible for developing and integrating significant portions of the robotics software stack to achieve these goals.

Regarding the sample projects noted on the job application page, I spent a large portion of my PhD working on combining inverse reinforcement learning with playful exploration of simple auxiliary tasks for learning difficult manipulation tasks \cite{ablett}. Being inverse reinforcement learning, there was no reward engineering at all for this work, and we specifically found that this approach resolved inherent exploration issues that crop up when using single-task inverse reinforcement learning. My latest set of papers from this line of research was based on removing the need for full-trajectory expert data and using examples of completed tasks, which are very easy to provide and ensure that suboptimal expert data doesn’t bias the policy towards poorer solutions.

I am currently based in Toronto, but I am willing to move for this position. Please don’t hesitate to reach out to me if you need further description of my background. Thank you again for your time.
